{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for checking\n",
    "1) Stability to biomass perturbations and\n",
    "2) Stability to invasion\n",
    "for the steady state GNE produced in the \n",
    "notebook \"ecoli_model_compute_ss_gne.ipynb\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as linalg\n",
    "import scipy.sparse as sparse\n",
    "import scipy.sparse.linalg as sp_linalg\n",
    "import scipy.io as sio\n",
    "import cvxpy as cp\n",
    "import time\n",
    "import gurobipy\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set solver to use with cvxpy. See \"Choosing a solver\" section here for using alternatives \n",
    "# to Gurobi: https://www.cvxpy.org/tutorial/advanced/index.html\n",
    "cp_solver = 'GUROBI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for model.\n",
    "directory = '../ModelFiles/FourSpecies'\n",
    "\n",
    "# S contains the stoichiometry matrices R_{k} and R_{k}^{ex} for each species k.\n",
    "S = sio.loadmat(directory + '/S.mat')['S']\n",
    "I = sio.loadmat(directory + '/I.mat')['I'][0][0]\n",
    "J = sio.loadmat(directory + '/J.mat')['J'][0][0]\n",
    "reaction_lb = sio.loadmat(directory + '/lb.mat')['lb']\n",
    "reaction_ub = sio.loadmat(directory + '/ub.mat')['ub']\n",
    "\n",
    "# Indices of reactions and metabolites for each species, needed because \n",
    "# cobra groups all metabolites and reactions into a single model.\n",
    "lumen_reactions_idx = sio.loadmat(directory + '/lumen_reactions_idx.mat')['lumen_reactions_idx'] - 1\n",
    "lumen_metabolites_idx = sio.loadmat(directory + '/lumen_metabolites_idx.mat')['lumen_metabolites_idx'] - 1\n",
    "lumen_reaction_names = sio.loadmat(directory + '/lumen_reactions.mat')['lumen_reactions']\n",
    "\n",
    "Ec1_reactions_idx = sio.loadmat(directory + '/Ec1_reactions_idx.mat')['Ec1_reactions_idx'] - 1\n",
    "Ec1_reaction_names = sio.loadmat(directory + '/Ec1_reactions.mat')['Ec1_reactions']\n",
    "Ec1_metabolites_idx = sio.loadmat(directory + '/Ec1_metabolites_idx.mat')['Ec1_metabolites_idx'] - 1\n",
    "Ec1_biomass_idx = sio.loadmat(directory + '/Ec1_biomass_idx.mat')['Ec1_biomass_idx'][0][0]-1\n",
    "\n",
    "Ec2_reactions_idx = sio.loadmat(directory + '/Ec2_reactions_idx.mat')['Ec2_reactions_idx'] - 1\n",
    "Ec2_reaction_names = sio.loadmat(directory + '/Ec2_reactions.mat')['Ec2_reactions']\n",
    "Ec2_metabolites_idx = sio.loadmat(directory + '/Ec2_metabolites_idx.mat')['Ec2_metabolites_idx'] - 1\n",
    "Ec2_biomass_idx = sio.loadmat(directory + '/Ec2_biomass_idx.mat')['Ec2_biomass_idx'][0][0]-1\n",
    "\n",
    "Ec3_reactions_idx = sio.loadmat(directory + '/Ec3_reactions_idx.mat')['Ec3_reactions_idx'] - 1\n",
    "Ec3_reaction_names = sio.loadmat(directory + '/Ec3_reactions.mat')['Ec3_reactions']\n",
    "Ec3_metabolites_idx = sio.loadmat(directory + '/Ec3_metabolites_idx.mat')['Ec3_metabolites_idx'] - 1\n",
    "Ec3_biomass_idx = sio.loadmat(directory + '/Ec3_biomass_idx.mat')['Ec3_biomass_idx'][0][0]-1\n",
    "\n",
    "Ec4_reactions_idx = sio.loadmat(directory + '/Ec4_reactions_idx.mat')['Ec4_reactions_idx'] - 1\n",
    "Ec4_reaction_names = sio.loadmat(directory + '/Ec4_reactions.mat')['Ec4_reactions']\n",
    "Ec4_metabolites_idx = sio.loadmat(directory + '/Ec4_metabolites_idx.mat')['Ec4_metabolites_idx'] - 1\n",
    "Ec4_biomass_idx = sio.loadmat(directory + '/Ec4_biomass_idx.mat')['Ec4_biomass_idx'][0][0]-1\n",
    "\n",
    "I1 = len(Ec1_metabolites_idx); I2 = len(Ec2_metabolites_idx); I3 = len(Ec3_metabolites_idx); I4 = len(Ec4_metabolites_idx)\n",
    "Jl = len(lumen_reactions_idx); J1 = len(Ec1_reactions_idx); J2 = len(Ec2_reactions_idx); J3 = len(Ec3_reactions_idx); J4 = len(Ec4_reactions_idx)\n",
    "\n",
    "Ec1_reaction_names = np.array([Ec1_reaction_names[i][0] for i in range(len(Ec1_reaction_names))])\n",
    "Ec2_reaction_names = np.array([Ec2_reaction_names[i][0] for i in range(len(Ec2_reaction_names))])\n",
    "Ec3_reaction_names = np.array([Ec3_reaction_names[i][0] for i in range(len(Ec3_reaction_names))])\n",
    "Ec4_reaction_names = np.array([Ec4_reaction_names[i][0] for i in range(len(Ec4_reaction_names))])\n",
    "lumen_reaction_names = np.array([lumen_reaction_names[i][0] for i in range(len(lumen_reaction_names))])\n",
    "\n",
    "# Create vectors that can be dotted with vector of reactions for each species \n",
    "# and pull out the biomass reaction.\n",
    "e1 = sparse.identity(J1 + Jl).tocsr()[:, Ec1_biomass_idx]; e2 = sparse.identity(J2 + Jl).tocsr()[:, Ec2_biomass_idx]\n",
    "e3 = sparse.identity(J3 + Jl).tocsr()[:, Ec3_biomass_idx]; e4 = sparse.identity(J4 + Jl).tocsr()[:, Ec4_biomass_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load steady state GNE generated in the \n",
    "# notebook titled 'ecoli_model_compute_ss_gne.ipynb'.\n",
    "death_rate = np.array([0.50])\n",
    "steady_states = pickle.load(open(\"steady_states.p\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stability(x1, bm1, x2, bm2, x3, bm3, x4, bm4, pert_size):\n",
    "    ''' Function for computing whether or not the steady state\n",
    "    GNE with biomasses [bm1, bm2, bm3, bm4] and fluxes \n",
    "    [x1, x2, x3, x4] is stable. If unstable, the function \n",
    "    also provides the size ofthe maximum eigenvalue and its \n",
    "    corresponding eigenvector, which gives an unstable \n",
    "    perturbation direction. \n",
    "    \n",
    "    pert_size is the size of the perturbations of \n",
    "    the upper and lower reaction bounds used \n",
    "    to ensure uniqueness of the dual solutions. '''\n",
    "\n",
    "    print('Starting stability function')\n",
    "    # Re-run best response problem with Gurobi/simplex method to get optimal basis.\n",
    "    \n",
    "    env = gurobipy.Env(empty=True)\n",
    "    env.setParam(\"OutputFlag\",0)\n",
    "    env.start()\n",
    "    \n",
    "    #print('Resolving Ec1 problem.')\n",
    "    # Ec1's problem.\n",
    "    m1 = gurobipy.Model(\"Ec1\", env=env)\n",
    "\n",
    "    # Create variables.\n",
    "    lb1 = reaction_lb[Ec1_reactions_idx.flatten()].flatten()\n",
    "    ub1 = reaction_ub[Ec1_reactions_idx.flatten()].flatten()\n",
    "    \n",
    "    lb1_pert = np.random.random((J1, 1))\n",
    "    lbl_pert = np.random.random((Jl, 1))\n",
    "    ub1_pert = np.random.random((J1, 1))\n",
    "    \n",
    "    lb1 = lb1 - pert_size * lb1_pert.flatten()\n",
    "    ub1 = ub1 + pert_size * ub1_pert.flatten()\n",
    "\n",
    "    rxns1 = m1.addMVar(shape=J1, name='rxns1', lb=lb1, ub=ub1);\n",
    "\n",
    "    lb1_ex = (reaction_lb[lumen_reactions_idx.flatten()].flatten() - bm2 * x2[J2:].flatten() - bm3 * x3[J3:].flatten() - bm4 * x4[J4:].flatten()) / bm1\n",
    "    ub1_ex = (reaction_ub[lumen_reactions_idx.flatten()].flatten() - bm2 * x2[J2:].flatten() - bm3 * x3[J3:].flatten() - bm4 * x4[J4:].flatten()) / bm1\n",
    "    \n",
    "    lb1_ex = lb1_ex - pert_size * lbl_pert.flatten()\n",
    "    \n",
    "    rxns1_ex = m1.addMVar(shape=Jl, name='rxns1_ex', lb=lb1_ex, ub=ub1_ex);\n",
    "\n",
    "    # Set objective.\n",
    "    m1.setObjective(e1.toarray()[0:J1].T @ rxns1, gurobipy.GRB.MAXIMIZE);\n",
    "\n",
    "    # Make constraints.\n",
    "    S1 = S[np.concatenate([Ec1_metabolites_idx, lumen_metabolites_idx]).flatten(), :]\n",
    "    S1_ex = S1[:, lumen_reactions_idx.flatten()]\n",
    "    S1 = S1[:, Ec1_reactions_idx.flatten()]\n",
    "    m1.addConstr(S1 @ rxns1 + S1_ex @ rxns1_ex == np.zeros((S1.shape[0],)), name='internal_fba1');\n",
    "\n",
    "    # Solve.\n",
    "    m1.params.Method = 0;\n",
    "    m1.update();\n",
    "    m1.optimize();\n",
    "    \n",
    "    #print('Resolving Ec2 problem.')\n",
    "    # Ec2's problem.\n",
    "    m2 = gurobipy.Model(\"Ec2\", env=env)\n",
    "\n",
    "    # Create variables.\n",
    "    lb2 = reaction_lb[Ec2_reactions_idx.flatten()].flatten()\n",
    "    ub2 = reaction_ub[Ec2_reactions_idx.flatten()].flatten()\n",
    "    \n",
    "    lb2_pert = np.random.random((J2, 1))\n",
    "    lbl_pert = np.random.random((Jl, 1))\n",
    "    ub2_pert = np.random.random((J2, 1))\n",
    "    \n",
    "    lb2 = lb2 - pert_size * lb2_pert.flatten()\n",
    "    ub2 = ub2 + pert_size * ub2_pert.flatten()\n",
    "    \n",
    "    rxns2 = m2.addMVar(shape=J2, name='rxns2', lb=lb2, ub=ub2);\n",
    "\n",
    "    lb2_ex = (reaction_lb[lumen_reactions_idx.flatten()].flatten() - bm1 * x1[J1:].flatten() - bm3 * x3[J3:].flatten() - bm4 * x4[J4:].flatten()) / bm2\n",
    "    ub2_ex = (reaction_ub[lumen_reactions_idx.flatten()].flatten() - bm1 * x1[J1:].flatten() - bm3 * x3[J3:].flatten() - bm4 * x4[J4:].flatten()) / bm2\n",
    "    \n",
    "    lb2_ex = lb2_ex - pert_size * lbl_pert.flatten()\n",
    "    \n",
    "    rxns2_ex = m2.addMVar(shape=Jl, name='rxns2_ex', lb=lb2_ex, ub=ub2_ex);\n",
    "\n",
    "    # Set objective.\n",
    "    m2.setObjective(e2.toarray()[0:J2].T @ rxns2, gurobipy.GRB.MAXIMIZE);\n",
    "\n",
    "    # Make constraints.\n",
    "    S2 = S[np.concatenate([Ec2_metabolites_idx, lumen_metabolites_idx]).flatten(), :]\n",
    "    S2_ex = S2[:, lumen_reactions_idx.flatten()]\n",
    "    S2 = S2[:, Ec2_reactions_idx.flatten()]\n",
    "    m2.addConstr(S2 @ rxns2 + S2_ex @ rxns2_ex == np.zeros((S2.shape[0],)), name='internal_fba2');\n",
    "\n",
    "    m2.params.Method = 0;\n",
    "    m2.update();\n",
    "    m2.optimize();\n",
    "    \n",
    "    #print('Resolving Ec3 problem.')\n",
    "    # Ec3's problem.\n",
    "    m3 = gurobipy.Model(\"Ec3\", env=env)\n",
    "\n",
    "    # Create variables.\n",
    "    lb3 = reaction_lb[Ec3_reactions_idx.flatten()].flatten()\n",
    "    ub3 = reaction_ub[Ec3_reactions_idx.flatten()].flatten()\n",
    "    \n",
    "    lb3_pert = np.random.random((J3,1))\n",
    "    lbl_pert = np.random.random((Jl,1))\n",
    "    ub3_pert = np.random.random((J3,1))\n",
    "    \n",
    "    lb3 = lb3 - pert_size * lb3_pert.flatten()\n",
    "    ub3 = ub3 + pert_size * ub3_pert.flatten()\n",
    "    \n",
    "    rxns3 = m3.addMVar(shape=J3, name='rxns3', lb=lb3, ub=ub3);\n",
    "\n",
    "    lb3_ex = (reaction_lb[lumen_reactions_idx.flatten()].flatten() - bm2 * x2[J2:].flatten() - bm1 * x1[J1:].flatten() - bm4 * x4[J4:].flatten()) / bm3\n",
    "    ub3_ex = (reaction_ub[lumen_reactions_idx.flatten()].flatten() - bm2 * x2[J2:].flatten() - bm1 * x1[J1:].flatten() - bm4 * x4[J4:].flatten()) / bm3\n",
    "    \n",
    "    lb3_ex = lb3_ex - pert_size * lbl_pert.flatten()\n",
    "    \n",
    "    rxns3_ex = m3.addMVar(shape=Jl, name='rxns3_ex', lb=lb3_ex, ub=ub3_ex);\n",
    "\n",
    "    # Set objective.\n",
    "    m3.setObjective(e3.toarray()[0:J3].T @ rxns3, gurobipy.GRB.MAXIMIZE);\n",
    "\n",
    "    # Make constraints.\n",
    "    S3 = S[np.concatenate([Ec3_metabolites_idx, lumen_metabolites_idx]).flatten(), :]\n",
    "    S3_ex = S3[:, lumen_reactions_idx.flatten()]\n",
    "    S3 = S3[:, Ec3_reactions_idx.flatten()]\n",
    "    m3.addConstr(S3 @ rxns3 + S3_ex @ rxns3_ex == np.zeros((S3.shape[0],)), name='internal_fba3');\n",
    "\n",
    "    m3.params.Method = 0;\n",
    "    m3.update();\n",
    "    m3.optimize();\n",
    "    \n",
    "    #print('Resolving Ec4 problem.')\n",
    "    # Ec4's problem.\n",
    "    m4 = gurobipy.Model(\"Ec4\", env=env)\n",
    "\n",
    "    # Create variables.\n",
    "    lb4 = reaction_lb[Ec4_reactions_idx.flatten()].flatten()\n",
    "    ub4 = reaction_ub[Ec4_reactions_idx.flatten()].flatten()\n",
    "    \n",
    "    lb4_pert = np.random.random((J4,1))\n",
    "    lbl_pert = np.random.random((Jl,1))\n",
    "    ub4_pert = np.random.random((J4,1))\n",
    "    \n",
    "    lb4 = lb4 - pert_size * lb4_pert.flatten()\n",
    "    ub4 = ub4 + pert_size * ub4_pert.flatten()\n",
    "    \n",
    "    rxns4 = m4.addMVar(shape=J4, name='rxns4', lb=lb4, ub=ub4);\n",
    "\n",
    "    lb4_ex = (reaction_lb[lumen_reactions_idx.flatten()].flatten() - bm2 * x2[J2:].flatten() - bm3 * x3[J3:].flatten() - bm1 * x1[J1:].flatten()) / bm4\n",
    "    ub4_ex = (reaction_ub[lumen_reactions_idx.flatten()].flatten() - bm2 * x2[J2:].flatten() - bm3 * x3[J3:].flatten() - bm1 * x1[J1:].flatten()) / bm4\n",
    "    \n",
    "    lb4_ex = lb4_ex - pert_size * lbl_pert.flatten()\n",
    "    \n",
    "    rxns4_ex = m4.addMVar(shape=Jl, name='rxns4_ex', lb=lb4_ex, ub=ub4_ex);\n",
    "\n",
    "    # Set objective.\n",
    "    m4.setObjective(e4.toarray()[0:J4].T @ rxns4, gurobipy.GRB.MAXIMIZE);\n",
    "\n",
    "    # Make constraints.\n",
    "    S4 = S[np.concatenate([Ec4_metabolites_idx, lumen_metabolites_idx]).flatten(), :]\n",
    "    S4_ex = S4[:, lumen_reactions_idx.flatten()]\n",
    "    S4 = S4[:, Ec4_reactions_idx.flatten()]\n",
    "    m4.addConstr(S4 @ rxns4 + S4_ex @ rxns4_ex == np.zeros((S4.shape[0],)), name='internal_fba4');\n",
    "\n",
    "    m4.params.Method = 0;\n",
    "    m4.update();\n",
    "    m4.optimize();\n",
    "    \n",
    "    # Check degeneracy.\n",
    "    primal_basis1 = rxns1.VBasis == 0\n",
    "    primal_basis1_ex = rxns1_ex.VBasis == 0\n",
    "    \n",
    "    active_basic1_lb = np.where(rxns1.X[primal_basis1] - lb1[primal_basis1] == 0)[0]\n",
    "    active_basic1_ub = np.where(ub1[primal_basis1] - rxns1.X[primal_basis1] == 0)[0]\n",
    "    active_basic1_ex_lb = np.where(rxns1_ex.X[primal_basis1_ex] - lb1_ex[primal_basis1_ex] == 0)[0]\n",
    "    active_basic1_ex_ub = np.where(ub1_ex[primal_basis1_ex] - rxns1_ex.X[primal_basis1_ex] == 0)[0]\n",
    "    \n",
    "    if len(active_basic1_lb) == 0 and len(active_basic1_ub) == 0 and len(active_basic1_ex_lb) == 0 and len(active_basic1_ex_ub) == 0:\n",
    "        degenerate = False\n",
    "    else:\n",
    "        degenerate = True\n",
    "        \n",
    "    if degenerate:\n",
    "        raise Exception('Ec1 problem is degenerate')\n",
    "    \n",
    "    primal_basis2 = rxns2.VBasis == 0\n",
    "    primal_basis2_ex = rxns2_ex.VBasis == 0\n",
    "    \n",
    "    active_basic2_lb = np.where(rxns2.X[primal_basis2] - lb2[primal_basis2] == 0)[0]\n",
    "    active_basic2_ub = np.where(ub2[primal_basis2] - rxns2.X[primal_basis2] == 0)[0]\n",
    "    active_basic2_ex_lb = np.where(rxns2_ex.X[primal_basis2_ex] - lb2_ex[primal_basis2_ex] == 0)[0]\n",
    "    active_basic2_ex_ub = np.where(ub2_ex[primal_basis2_ex] - rxns2_ex.X[primal_basis2_ex] == 0)[0]\n",
    "    \n",
    "    if len(active_basic2_lb) == 0 and len(active_basic2_ub) == 0 and len(active_basic2_ex_lb) == 0 and len(active_basic2_ex_ub) == 0:\n",
    "        degenerate = False\n",
    "    else:\n",
    "        degenerate = True\n",
    "        \n",
    "    if degenerate:\n",
    "        raise Exception('Ec2 problem is degenerate')\n",
    "    \n",
    "    primal_basis3 = rxns3.VBasis == 0\n",
    "    primal_basis3_ex = rxns3_ex.VBasis == 0\n",
    "    \n",
    "    active_basic3_lb = np.where(rxns3.X[primal_basis3] - lb3[primal_basis3] == 0)[0]\n",
    "    active_basic3_ub = np.where(ub3[primal_basis3] - rxns3.X[primal_basis3] == 0)[0]\n",
    "    active_basic3_ex_lb = np.where(rxns3_ex.X[primal_basis3_ex] - lb3_ex[primal_basis3_ex] == 0)[0]\n",
    "    active_basic3_ex_ub = np.where(ub3_ex[primal_basis3_ex] - rxns3_ex.X[primal_basis3_ex] == 0)[0]\n",
    "    \n",
    "    if len(active_basic3_lb) == 0 and len(active_basic3_ub) == 0 and len(active_basic3_ex_lb) == 0 and len(active_basic3_ex_ub) == 0:\n",
    "        degenerate = False\n",
    "    else:\n",
    "        degenerate = True\n",
    "        \n",
    "    if degenerate:\n",
    "        raise Exception('Ec3 problem is degenerate')\n",
    "    \n",
    "    primal_basis4 = rxns4.VBasis == 0\n",
    "    primal_basis4_ex = rxns4_ex.VBasis == 0\n",
    "    \n",
    "    active_basic4_lb = np.where(rxns4.X[primal_basis4] - lb4[primal_basis4] == 0)[0]\n",
    "    active_basic4_ub = np.where(ub4[primal_basis4] - rxns4.X[primal_basis4] == 0)[0]\n",
    "    active_basic4_ex_lb = np.where(rxns4_ex.X[primal_basis4_ex] - lb4_ex[primal_basis4_ex] == 0)[0]\n",
    "    active_basic4_ex_ub = np.where(ub4_ex[primal_basis4_ex] - rxns4_ex.X[primal_basis4_ex] == 0)[0]\n",
    "    \n",
    "    if len(active_basic4_lb) == 0 and len(active_basic4_ub) == 0 and len(active_basic4_ex_lb) == 0 and len(active_basic4_ex_ub) == 0:\n",
    "        degenerate = False\n",
    "    else:\n",
    "        degenerate = True\n",
    "        \n",
    "    if degenerate:\n",
    "        raise Exception('Ec4 problem is degenerate')\n",
    "\n",
    "    #print('Get active constraints, free variables, and dual values.')\n",
    "    E = np.where(bm1 * rxns1_ex.X + bm2 * rxns2_ex.X + bm3 * rxns3_ex.X + bm4 * rxns4_ex.X - reaction_lb[lumen_reactions_idx.flatten()].flatten() < 1e-6)[0]\n",
    "    \n",
    "    U1 = np.where(ub1 - rxns1.X < 1e-6)[0]\n",
    "    L1 = np.where(rxns1.X - lb1 < 1e-6)[0]\n",
    "    F1 = np.where(np.logical_and(~np.isin(np.arange(J1), U1), ~np.isin(np.arange(J1), L1)))[0]\n",
    "    \n",
    "    U2 = np.where(ub2 - rxns2.X < 1e-6)[0]\n",
    "    L2 = np.where(rxns2.X - lb2 < 1e-6)[0]\n",
    "    F2 = np.where(np.logical_and(~np.isin(np.arange(J2), U2), ~np.isin(np.arange(J2), L2)))[0]\n",
    "    \n",
    "    U3 = np.where(ub3 - rxns3.X < 1e-6)[0]\n",
    "    L3 = np.where(rxns3.X - lb3 < 1e-6)[0]\n",
    "    F3 = np.where(np.logical_and(~np.isin(np.arange(J3), U3), ~np.isin(np.arange(J3), L3)))[0]\n",
    "    \n",
    "    U4 = np.where(ub4 - rxns4.X < 1e-6)[0]\n",
    "    L4 = np.where(rxns4.X - lb4 < 1e-6)[0]\n",
    "    F4 = np.where(np.logical_and(~np.isin(np.arange(J4), U4), ~np.isin(np.arange(J4), L4)))[0]\n",
    "\n",
    "    lambda1 = rxns1_ex.RC\n",
    "    lambda2 = rxns2_ex.RC\n",
    "    lambda3 = rxns3_ex.RC\n",
    "    lambda4 = rxns4_ex.RC\n",
    "    lambdas = [lambda1, lambda2, lambda3, lambda4]\n",
    "    biomasses = [bm1, bm2, bm3, bm4]\n",
    "    \n",
    "    lambda1_L = np.zeros((len(rxns1.X,)))\n",
    "    lambda1_L[np.where(rxns1.VBasis == -1)[0]] = rxns1.RC[np.where(rxns1.VBasis == -1)[0]]\n",
    "    lambda1_U = np.zeros((len(rxns1.X,)))\n",
    "    lambda1_U[np.where(rxns1.VBasis == -2)[0]] = rxns1.RC[np.where(rxns1.VBasis == -2)[0]]\n",
    "    \n",
    "    lambda2_L = np.zeros((len(rxns2.X,)))\n",
    "    lambda2_L[np.where(rxns2.VBasis == -1)[0]] = rxns2.RC[np.where(rxns2.VBasis == -1)[0]]\n",
    "    lambda2_U = np.zeros((len(rxns2.X,)))\n",
    "    lambda2_U[np.where(rxns2.VBasis == -2)[0]] = rxns2.RC[np.where(rxns2.VBasis == -2)[0]]\n",
    "    \n",
    "    lambda3_L = np.zeros((len(rxns3.X,)))\n",
    "    lambda3_L[np.where(rxns3.VBasis == -1)[0]] = rxns3.RC[np.where(rxns3.VBasis == -1)[0]]\n",
    "    lambda3_U = np.zeros((len(rxns3.X,)))\n",
    "    lambda3_U[np.where(rxns3.VBasis == -2)[0]] = rxns3.RC[np.where(rxns3.VBasis == -2)[0]]\n",
    "    \n",
    "    lambda4_L = np.zeros((len(rxns4.X,)))\n",
    "    lambda4_L[np.where(rxns4.VBasis == -1)[0]] = rxns4.RC[np.where(rxns4.VBasis == -1)[0]]\n",
    "    lambda4_U = np.zeros((len(rxns4.X,)))\n",
    "    lambda4_U[np.where(rxns4.VBasis == -2)[0]] = rxns4.RC[np.where(rxns4.VBasis == -2)[0]]\n",
    "    \n",
    "    lambdas_L = [lambda1_L, lambda2_L, lambda3_L, lambda4_L]\n",
    "    lambdas_U = [lambda1_U, lambda2_U, lambda3_U, lambda4_U]\n",
    "    \n",
    "    x1 = np.zeros((x1.shape[0],))\n",
    "    x1[0:J1] = rxns1.X\n",
    "    x1[J1:] = rxns1_ex.X\n",
    "    \n",
    "    x2 = np.zeros((x2.shape[0],))\n",
    "    x2[0:J2] = rxns2.X\n",
    "    x2[J2:] = rxns2_ex.X\n",
    "    \n",
    "    x3 = np.zeros((x3.shape[0],))\n",
    "    x3[0:J3] = rxns3.X\n",
    "    x3[J3:] = rxns3_ex.X\n",
    "    \n",
    "    x4 = np.zeros((x4.shape[0],))\n",
    "    x4[0:J4] = rxns4.X\n",
    "    x4[J4:] = rxns4_ex.X\n",
    "    \n",
    "    x_values = [x1, x2, x3, x4]\n",
    "    \n",
    "    I_values = [I1, I2, I3, I4]\n",
    "    J_values = [J1, J2, J3, J4]\n",
    "    \n",
    "    b1 = (1/bm1) * (reaction_lb[lumen_reactions_idx.flatten()].flatten() - (bm2 * x_values[1].flatten()[J_values[1]:] + bm3 * x_values[2].flatten()[J_values[2]:] + bm4 * x_values[3].flatten()[J_values[3]:]))\n",
    "    b2 = (1/bm2) * (reaction_lb[lumen_reactions_idx.flatten()].flatten() - (bm1 * x_values[0].flatten()[J_values[0]:] + bm3 * x_values[2].flatten()[J_values[2]:] + bm4 * x_values[3].flatten()[J_values[3]:]))\n",
    "    b3 = (1/bm3) * (reaction_lb[lumen_reactions_idx.flatten()].flatten() - (bm2 * x_values[1].flatten()[J_values[1]:] + bm1 * x_values[0].flatten()[J_values[0]:] + bm4 * x_values[3].flatten()[J_values[3]:]))\n",
    "    b4 = (1/bm4) * (reaction_lb[lumen_reactions_idx.flatten()].flatten() - (bm2 * x_values[1].flatten()[J_values[1]:] + bm3 * x_values[2].flatten()[J_values[2]:] + bm1 * x_values[0].flatten()[J_values[0]:]))\n",
    "    b_values = [b1, b2, b3, b4]\n",
    "                    \n",
    "    metabolite_indices = [Ec1_metabolites_idx.flatten(), Ec2_metabolites_idx.flatten(), Ec3_metabolites_idx.flatten(), Ec4_metabolites_idx.flatten()]\n",
    "    reaction_indices = [Ec1_reactions_idx.flatten(), Ec2_reactions_idx.flatten(), Ec3_reactions_idx.flatten(), Ec4_reactions_idx.flatten()]\n",
    "\n",
    "    free_var_indices = [F1, F2, F3, F4]\n",
    "    \n",
    "    num_vars = 4*4 + 4*4*Jl + 4*np.sum([free_var_indices[l].shape[0] for l in range(4)])\n",
    "    num_constraints = 4*4 + 4*4*E.shape[0] + 4*np.sum(I_values) + 4*4*Jl\n",
    "    \n",
    "    A_stable = sparse.csr_matrix((num_constraints, num_vars))\n",
    "    b_stable = np.zeros((num_constraints,))\n",
    "    \n",
    "    #print('First block of constructing A')\n",
    "    # Make constraints for partials of h_{k}(x) values.\n",
    "    for k in range(4):\n",
    "        for j in range(4):\n",
    "            row_kj = np.zeros((num_vars,))\n",
    "            row_kj[4*k + j] = 1\n",
    "            for l in range(4):\n",
    "                if l != k:\n",
    "                    row_kj[(4*4 + (4*l + j)*Jl):(4*4 + (4*l + j + 1)*Jl)] = (biomasses[l] / biomasses[k]) * lambdas[k].T\n",
    "\n",
    "            A_stable[4*k + j, :] = row_kj\n",
    "\n",
    "            if j == k:\n",
    "                b_stable[4*k + j] = -(1/biomasses[k]) * lambdas[k].T.dot(b_values[k].flatten())\n",
    "            else:\n",
    "                b_stable[4*k + j] = -(1/biomasses[k]) * lambdas[k].T.dot(x_values[j][J_values[j]:])\n",
    "    #print('Second block of constructing A.')\n",
    "    # Make constraints for partials of R_{k}^{E} \\nu_{k}^{ex} with respect to x_{j}.\n",
    "    for k in range(4):\n",
    "        for j in range(4):\n",
    "            block_kj = np.zeros((E.shape[0], num_vars))\n",
    "            block_kj[:, 4*4 + (4*k + j)*Jl + E] = np.eye(E.shape[0])\n",
    "\n",
    "            for l in range(4):\n",
    "                if l != k:\n",
    "                    block_kj[:, 4*4 + (4*l + j)*Jl + E] = (biomasses[l] / biomasses[k]) * np.eye(E.shape[0])\n",
    "\n",
    "            A_stable[(4*4 + (4*k + j)*E.shape[0]):(4*4 + (4*k + j + 1)*E.shape[0]), :] = sparse.csr_matrix(block_kj)\n",
    "\n",
    "            if j == k:\n",
    "                b_stable[(4*4 + (4*k + j)*E.shape[0]):(4*4 + (4*k + j + 1)*E.shape[0])] = -(1 / biomasses[k]) * b_values[k].flatten()[E]\n",
    "            else:\n",
    "                b_stable[(4*4 + (4*k + j)*E.shape[0]):(4*4 + (4*k + j + 1)*E.shape[0])] = -(1 / biomasses[k]) * x_values[j][J_values[j]:].flatten()[E]\n",
    "    #print('Third block of constructing A.')\n",
    "    # Make constraints for partials of R_{k}^{F} \\nu_{k}(F_{k}) and R_{k}^{ex} \\nu_{k}^{ex}\n",
    "    # with respect to x_{j}.\n",
    "    for k in range(4):\n",
    "        for j in range(4):\n",
    "            A_kj_row_idx_start = int(4*4 + 4*4*E.shape[0] + np.sum([4*(I_values[w]+Jl) for w in range(k)]) + j*(I_values[k]+Jl))\n",
    "\n",
    "            block_kj = S[:, lumen_reactions_idx.flatten()]\n",
    "            block_kj = block_kj[np.concatenate([metabolite_indices[k], lumen_metabolites_idx.flatten()]).flatten(), :]\n",
    "            A_stable[A_kj_row_idx_start:(A_kj_row_idx_start + I_values[k] + Jl), (4*4 + (4*k + j)*Jl):(4*4 + (4*k + j + 1)*Jl)] = sparse.csr_matrix(block_kj)\n",
    "\n",
    "            block_kj_internal = S[:, reaction_indices[k][free_var_indices[k]]]\n",
    "            block_kj_internal = block_kj_internal[np.concatenate([metabolite_indices[k], lumen_metabolites_idx.flatten()]).flatten(), :]\n",
    "            A_stable[A_kj_row_idx_start:(A_kj_row_idx_start + I_values[k] + Jl),\n",
    "                     int((4*4 + 4*4*Jl + 4*np.sum([free_var_indices[w].shape[0] for w in range(k)]) + j*free_var_indices[k].shape[0])):int((4*4 + 4*4*Jl + 4*np.sum([free_var_indices[w].shape[0] for w in range(k)]) + (j+1)*free_var_indices[k].shape[0]))] = sparse.csr_matrix(block_kj_internal)\n",
    "\n",
    "    #print('System of equations set up')\n",
    "    result = sp_linalg.lsqr(A_stable,b_stable,atol=1e-6,btol=1e-6)[0]\n",
    "    #print('Sstem of equations solved')\n",
    "    \n",
    "    # Row k of h_vals gives values of partials of h_{k}.\n",
    "    h_vals = np.zeros((4,4))\n",
    "    for k in range(4):\n",
    "        h_vals[k,:] = result[k*4:(k+1)*4]\n",
    "        \n",
    "    # Now construct the matrix M used to check stability.\n",
    "    # Row k of M gives values of M_{k,j} for j = 0,1,2,3.\n",
    "    M = np.zeros((4,4))\n",
    "    for k in range(4):\n",
    "        M[k,:] = biomasses[k] * h_vals[k,:]\n",
    "        \n",
    "    # Compute eigenvalues of M. If real part of every eigenvalue of \n",
    "    # M is less than 0, then we have a stable steady state.\n",
    "    #print('Eigenvalues computed')\n",
    "    #eigs = linalg.eig(M)[0]\n",
    "    eigs, vecs = linalg.eig(M)\n",
    "\n",
    "    if np.max(eigs) > -1e-4:\n",
    "        stable = False\n",
    "    else:\n",
    "        stable = True\n",
    "    \n",
    "    max_eig_index = np.argmax(eigs)\n",
    "\n",
    "    print('eigs: ', eigs)\n",
    "    print('\\n')\n",
    "    print('vecs: ', vecs)\n",
    "\n",
    "    #return (stable, np.max(eigs))\n",
    "    return (stable, eigs[max_eig_index], vecs[max_eig_index])\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_start_time = time.time()\n",
    "\n",
    "stable_steady_states = []\n",
    "unstable_steady_states = []\n",
    "for i in range(len(steady_states)):\n",
    "    print('i: ', i)\n",
    "    target_bm, x1, x2, x3, x4 = steady_states[i]\n",
    "    try:\n",
    "        stable, max_eig = stability(x1, target_bm[0], x2, target_bm[1], x3, target_bm[2], x4, target_bm[3], 1e-8)\n",
    "        if stable:\n",
    "            stable_steady_states.append((target_bm, x1, x2, x3, x4))\n",
    "        else:\n",
    "            unstable_steady_states.append((target_bm, x1, x2, x3, x4))\n",
    "    except:\n",
    "        print('\\n')\n",
    "        print('In except')\n",
    "        print('\\n')\n",
    "        stable, max_eig = stability(x1, target_bm[0], x2, target_bm[1], x3, target_bm[2], x4, target_bm[3], 1e-6)\n",
    "        if stable:\n",
    "            stable_steady_states.append((target_bm, x1, x2, x3, x4))\n",
    "        else:\n",
    "            unstable_steady_states.append((target_bm, x1, x2, x3, x4))\n",
    "\n",
    "total_end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(stable_steady_states, open(\"stable_steady_states.p\", \"wb\"))\n",
    "pickle.dump(unstable_steady_states, open(\"unstable_steady_states.p\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute whether or not each of the computed \n",
    "steady state GNE is stable to the invasion of \n",
    "a fifth *E. coli* mutant described in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for five EColi model to look at stability to invasion.\n",
    "directory = '../ModelFiles/FiveSpecies'\n",
    "\n",
    "# S contains the stoichiometry matrices R_{k} and R_{k}^{ex} for each species k.\n",
    "S = sio.loadmat(directory + '/S.mat')['S']\n",
    "I = sio.loadmat(directory + '/I.mat')['I'][0][0]\n",
    "J = sio.loadmat(directory + '/J.mat')['J'][0][0]\n",
    "reaction_lb = sio.loadmat(directory + '/lb.mat')['lb']\n",
    "reaction_ub = sio.loadmat(directory + '/ub.mat')['ub']\n",
    "\n",
    "# Indices of reactions and metabolites for each species, needed because \n",
    "# cobra groups all metabolites and reactions into a single model.\n",
    "lumen_reactions_idx = sio.loadmat(directory + '/lumen_reactions_idx.mat')['lumen_reactions_idx'] - 1\n",
    "lumen_metabolites_idx = sio.loadmat(directory + '/lumen_metabolites_idx.mat')['lumen_metabolites_idx'] - 1\n",
    "lumen_reaction_names = sio.loadmat(directory + '/lumen_reactions.mat')['lumen_reactions']\n",
    "\n",
    "Ec1_reactions_idx = sio.loadmat(directory + '/Ec1_reactions_idx.mat')['Ec1_reactions_idx'] - 1\n",
    "Ec1_reaction_names = sio.loadmat(directory + '/Ec1_reactions.mat')['Ec1_reactions']\n",
    "Ec1_metabolites_idx = sio.loadmat(directory + '/Ec1_metabolites_idx.mat')['Ec1_metabolites_idx'] - 1\n",
    "Ec1_biomass_idx = sio.loadmat(directory + '/Ec1_biomass_idx.mat')['Ec1_biomass_idx'][0][0]-1\n",
    "\n",
    "Ec2_reactions_idx = sio.loadmat(directory + '/Ec2_reactions_idx.mat')['Ec2_reactions_idx'] - 1\n",
    "Ec2_reaction_names = sio.loadmat(directory + '/Ec2_reactions.mat')['Ec2_reactions']\n",
    "Ec2_metabolites_idx = sio.loadmat(directory + '/Ec2_metabolites_idx.mat')['Ec2_metabolites_idx'] - 1\n",
    "Ec2_biomass_idx = sio.loadmat(directory + '/Ec2_biomass_idx.mat')['Ec2_biomass_idx'][0][0]-1\n",
    "\n",
    "Ec3_reactions_idx = sio.loadmat(directory + '/Ec3_reactions_idx.mat')['Ec3_reactions_idx'] - 1\n",
    "Ec3_reaction_names = sio.loadmat(directory + '/Ec3_reactions.mat')['Ec3_reactions']\n",
    "Ec3_metabolites_idx = sio.loadmat(directory + '/Ec3_metabolites_idx.mat')['Ec3_metabolites_idx'] - 1\n",
    "Ec3_biomass_idx = sio.loadmat(directory + '/Ec3_biomass_idx.mat')['Ec3_biomass_idx'][0][0]-1\n",
    "\n",
    "Ec4_reactions_idx = sio.loadmat(directory + '/Ec4_reactions_idx.mat')['Ec4_reactions_idx'] - 1\n",
    "Ec4_reaction_names = sio.loadmat(directory + '/Ec4_reactions.mat')['Ec4_reactions']\n",
    "Ec4_metabolites_idx = sio.loadmat(directory + '/Ec4_metabolites_idx.mat')['Ec4_metabolites_idx'] - 1\n",
    "Ec4_biomass_idx = sio.loadmat(directory + '/Ec4_biomass_idx.mat')['Ec4_biomass_idx'][0][0]-1\n",
    "\n",
    "Ec5_reactions_idx = sio.loadmat(directory + '/Ec5_reactions_idx.mat')['Ec5_reactions_idx'] - 1\n",
    "Ec5_reaction_names = sio.loadmat(directory + '/Ec5_reactions.mat')['Ec5_reactions']\n",
    "Ec5_metabolites_idx = sio.loadmat(directory + '/Ec5_metabolites_idx.mat')['Ec5_metabolites_idx'] - 1\n",
    "Ec5_biomass_idx = sio.loadmat(directory + '/Ec5_biomass_idx.mat')['Ec5_biomass_idx'][0][0]-1\n",
    "\n",
    "I1 = len(Ec1_metabolites_idx); I2 = len(Ec2_metabolites_idx); I3 = len(Ec3_metabolites_idx); I4 = len(Ec4_metabolites_idx); I5 = len(Ec5_metabolites_idx)\n",
    "Jl = len(lumen_reactions_idx); J1 = len(Ec1_reactions_idx); J2 = len(Ec2_reactions_idx); J3 = len(Ec3_reactions_idx); J4 = len(Ec4_reactions_idx); J5 = len(Ec5_reactions_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ec1_reaction_names = np.array([Ec1_reaction_names[i][0] for i in range(len(Ec1_reaction_names))])\n",
    "Ec2_reaction_names = np.array([Ec2_reaction_names[i][0] for i in range(len(Ec2_reaction_names))])\n",
    "Ec3_reaction_names = np.array([Ec3_reaction_names[i][0] for i in range(len(Ec3_reaction_names))])\n",
    "Ec4_reaction_names = np.array([Ec4_reaction_names[i][0] for i in range(len(Ec4_reaction_names))])\n",
    "Ec5_reaction_names = np.array([Ec5_reaction_names[i][0] for i in range(len(Ec5_reaction_names))])\n",
    "lumen_reaction_names = np.array([lumen_reaction_names[i][0] for i in range(len(lumen_reaction_names))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectors that can be dotted with vector of reactions for each species \n",
    "# and pull out the biomass reaction.\n",
    "e1 = sparse.identity(J1 + Jl).tocsr()[:, Ec1_biomass_idx]; e2 = sparse.identity(J2 + Jl).tocsr()[:, Ec2_biomass_idx]\n",
    "e3 = sparse.identity(J3 + Jl).tocsr()[:, Ec3_biomass_idx]; e4 = sparse.identity(J4 + Jl).tocsr()[:, Ec4_biomass_idx]\n",
    "e5 = sparse.identity(J5 + Jl).tocsr()[:, Ec5_biomass_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invaded_steady_states = []\n",
    "uninvaded_steady_states = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invasion_stability_opt(bm1, bm2, bm3, bm4, B1, B2, B3, B4, E):\n",
    "    ''' Determines stability of invasion to \n",
    "    a new species by solving problem (24) \n",
    "    in the paper. '''\n",
    "    solution = cp.Variable((J5 + Jl, 1))\n",
    "    objective = e5.T @ solution\n",
    "    constraints = [S[:, np.concatenate([Ec5_reactions_idx, lumen_reactions_idx]).flatten()] @ solution == 0,\n",
    "                   solution[0:J5] >= reaction_lb[Ec5_reactions_idx.flatten()],\n",
    "                   solution[0:J5] <= reaction_ub[Ec5_reactions_idx.flatten()],\n",
    "                   (sparse.identity(Jl).tocsr() + bm1 * B1 + bm2 * B2 + bm3 * B3 + bm4 * B4)[E, :] @ solution[J5:] >= 0\n",
    "]\n",
    "    prob = cp.Problem(cp.Maximize(objective), constraints)\n",
    "    prob.solve(solver = cp_solver)\n",
    "    return prob.value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_B_mats(x1, x2, x3, x4, bm1, bm2, bm3, bm4, pert_size):\n",
    "    ''' Function for generating the matrices \n",
    "    B_k for all species k as given in the \n",
    "    proof of Lemma A.4. '''\n",
    "\n",
    "    # First, need to calculate B matrices.\n",
    "    # To do so, need to first calculate the Pi matrices.\n",
    "    # In order to do \\emph{that}, need to calculate the Omega matrices.\n",
    "    env = gurobipy.Env(empty=True)\n",
    "    env.setParam(\"OutputFlag\",0)\n",
    "    env.start()\n",
    "    \n",
    "    # Ec1's problem.\n",
    "    m1 = gurobipy.Model(\"Ec1\", env=env)\n",
    "\n",
    "    # Create variables.\n",
    "    lb1 = reaction_lb[Ec1_reactions_idx.flatten()].flatten()\n",
    "    ub1 = reaction_ub[Ec1_reactions_idx.flatten()].flatten()\n",
    "\n",
    "    lb1_pert = np.random.random((J1, 1))\n",
    "    lbl_pert = np.random.random((Jl, 1))\n",
    "    ub1_pert = np.random.random((J1, 1))\n",
    "\n",
    "    lb1 = lb1 - pert_size * lb1_pert.flatten()\n",
    "    ub1 = ub1 + pert_size * ub1_pert.flatten()\n",
    "\n",
    "    rxns1 = m1.addMVar(shape=J1, name='rxns1', lb=lb1, ub=ub1);\n",
    "\n",
    "    lb1_ex = (reaction_lb[lumen_reactions_idx.flatten()].flatten() - bm2 * x2[J2:].flatten() - bm3 * x3[J3:].flatten() - bm4 * x4[J4:].flatten()) / bm1\n",
    "    ub1_ex = (reaction_ub[lumen_reactions_idx.flatten()].flatten() - bm2 * x2[J2:].flatten() - bm3 * x3[J3:].flatten() - bm4 * x4[J4:].flatten()) / bm1\n",
    "\n",
    "    lb1_ex = lb1_ex - pert_size * lbl_pert.flatten()\n",
    "\n",
    "    rxns1_ex = m1.addMVar(shape=Jl, name='rxns1_ex', lb=lb1_ex, ub=ub1_ex);\n",
    "\n",
    "    # Set objective.\n",
    "    m1.setObjective(e1.toarray()[0:J1].T @ rxns1, gurobipy.GRB.MAXIMIZE);\n",
    "\n",
    "    # Make constraints.\n",
    "    S1 = S[np.concatenate([Ec1_metabolites_idx, lumen_metabolites_idx]).flatten(), :]\n",
    "    S1_ex = S1[:, lumen_reactions_idx.flatten()]\n",
    "    S1 = S1[:, Ec1_reactions_idx.flatten()]\n",
    "    m1.addConstr(S1 @ rxns1 + S1_ex @ rxns1_ex == np.zeros((S1.shape[0],)), name='internal_fba1');\n",
    "\n",
    "    m1.params.Method = 0;\n",
    "    m1.update();\n",
    "    m1.optimize();\n",
    "\n",
    "    # Ec2's problem.\n",
    "    m2 = gurobipy.Model(\"Ec2\", env=env)\n",
    "\n",
    "    # Create variables.\n",
    "    lb2 = reaction_lb[Ec2_reactions_idx.flatten()].flatten()\n",
    "    ub2 = reaction_ub[Ec2_reactions_idx.flatten()].flatten()\n",
    "\n",
    "    lb2_pert = np.random.random((J2, 1))\n",
    "    lbl_pert = np.random.random((Jl, 1))\n",
    "    ub2_pert = np.random.random((J2, 1))\n",
    "\n",
    "    lb2 = lb2 - pert_size * lb2_pert.flatten()\n",
    "    ub2 = ub2 + pert_size * ub2_pert.flatten()\n",
    "\n",
    "    rxns2 = m2.addMVar(shape=J2, name='rxns2', lb=lb2, ub=ub2);\n",
    "\n",
    "    lb2_ex = (reaction_lb[lumen_reactions_idx.flatten()].flatten() - bm1 * x1[J1:].flatten() - bm3 * x3[J3:].flatten() - bm4 * x4[J4:].flatten()) / bm2\n",
    "    ub2_ex = (reaction_ub[lumen_reactions_idx.flatten()].flatten() - bm1 * x1[J1:].flatten() - bm3 * x3[J3:].flatten() - bm4 * x4[J4:].flatten()) / bm2\n",
    "\n",
    "    lb2_ex = lb2_ex - pert_size * lbl_pert.flatten()\n",
    "\n",
    "    rxns2_ex = m2.addMVar(shape=Jl, name='rxns2_ex', lb=lb2_ex, ub=ub2_ex);\n",
    "\n",
    "    # Set objective.\n",
    "    m2.setObjective(e2.toarray()[0:J2].T @ rxns2, gurobipy.GRB.MAXIMIZE);\n",
    "\n",
    "    # Make constraints.\n",
    "    S2 = S[np.concatenate([Ec2_metabolites_idx, lumen_metabolites_idx]).flatten(), :]\n",
    "    S2_ex = S2[:, lumen_reactions_idx.flatten()]\n",
    "    S2 = S2[:, Ec2_reactions_idx.flatten()]\n",
    "    m2.addConstr(S2 @ rxns2 + S2_ex @ rxns2_ex == np.zeros((S2.shape[0],)), name='internal_fba2');\n",
    "\n",
    "    m2.params.Method = 0;\n",
    "    m2.update();\n",
    "    m2.optimize();\n",
    "\n",
    "    # Ec3's problem.\n",
    "    m3 = gurobipy.Model(\"Ec3\", env=env)\n",
    "\n",
    "    # Create variables.\n",
    "    lb3 = reaction_lb[Ec3_reactions_idx.flatten()].flatten()\n",
    "    ub3 = reaction_ub[Ec3_reactions_idx.flatten()].flatten()\n",
    "\n",
    "    lb3_pert = np.random.random((J3,1))\n",
    "    lbl_pert = np.random.random((Jl,1))\n",
    "    ub3_pert = np.random.random((J3,1))\n",
    "\n",
    "    lb3 = lb3 - pert_size * lb3_pert.flatten()\n",
    "    ub3 = ub3 + pert_size * ub3_pert.flatten()\n",
    "\n",
    "    rxns3 = m3.addMVar(shape=J3, name='rxns3', lb=lb3, ub=ub3);\n",
    "\n",
    "    lb3_ex = (reaction_lb[lumen_reactions_idx.flatten()].flatten() - bm2 * x2[J2:].flatten() - bm1 * x1[J1:].flatten() - bm4 * x4[J4:].flatten()) / bm3\n",
    "    ub3_ex = (reaction_ub[lumen_reactions_idx.flatten()].flatten() - bm2 * x2[J2:].flatten() - bm1 * x1[J1:].flatten() - bm4 * x4[J4:].flatten()) / bm3\n",
    "\n",
    "    lb3_ex = lb3_ex - pert_size * lbl_pert.flatten()\n",
    "\n",
    "    rxns3_ex = m3.addMVar(shape=Jl, name='rxns3_ex', lb=lb3_ex, ub=ub3_ex);\n",
    "\n",
    "    # Set objective.\n",
    "    m3.setObjective(e3.toarray()[0:J3].T @ rxns3, gurobipy.GRB.MAXIMIZE);\n",
    "\n",
    "    # Make constraints.\n",
    "    S3 = S[np.concatenate([Ec3_metabolites_idx, lumen_metabolites_idx]).flatten(), :]\n",
    "    S3_ex = S3[:, lumen_reactions_idx.flatten()]\n",
    "    S3 = S3[:, Ec3_reactions_idx.flatten()]\n",
    "    m3.addConstr(S3 @ rxns3 + S3_ex @ rxns3_ex == np.zeros((S3.shape[0],)), name='internal_fba3');\n",
    "\n",
    "    m3.params.Method = 0;\n",
    "    m3.update();\n",
    "    m3.optimize();\n",
    "\n",
    "    # Ec4's problem.\n",
    "    m4 = gurobipy.Model(\"Ec4\", env=env)\n",
    "\n",
    "    # Create variables.\n",
    "    lb4 = reaction_lb[Ec4_reactions_idx.flatten()].flatten()\n",
    "    ub4 = reaction_ub[Ec4_reactions_idx.flatten()].flatten()\n",
    "\n",
    "    lb4_pert = np.random.random((J4,1))\n",
    "    lbl_pert = np.random.random((Jl,1))\n",
    "    ub4_pert = np.random.random((J4,1))\n",
    "\n",
    "    lb4 = lb4 - pert_size * lb4_pert.flatten()\n",
    "    ub4 = ub4 + pert_size * ub4_pert.flatten()\n",
    "\n",
    "    rxns4 = m4.addMVar(shape=J4, name='rxns4', lb=lb4, ub=ub4);\n",
    "\n",
    "    lb4_ex = (reaction_lb[lumen_reactions_idx.flatten()].flatten() - bm2 * x2[J2:].flatten() - bm3 * x3[J3:].flatten() - bm1 * x1[J1:].flatten()) / bm4\n",
    "    ub4_ex = (reaction_ub[lumen_reactions_idx.flatten()].flatten() - bm2 * x2[J2:].flatten() - bm3 * x3[J3:].flatten() - bm1 * x1[J1:].flatten()) / bm4\n",
    "\n",
    "    lb4_ex = lb4_ex - pert_size * lbl_pert.flatten()\n",
    "\n",
    "    rxns4_ex = m4.addMVar(shape=Jl, name='rxns4_ex', lb=lb4_ex, ub=ub4_ex);\n",
    "\n",
    "    # Set objective.\n",
    "    m4.setObjective(e4.toarray()[0:J4].T @ rxns4, gurobipy.GRB.MAXIMIZE);\n",
    "\n",
    "    # Make constraints.\n",
    "    S4 = S[np.concatenate([Ec4_metabolites_idx, lumen_metabolites_idx]).flatten(), :]\n",
    "    S4_ex = S4[:, lumen_reactions_idx.flatten()]\n",
    "    S4 = S4[:, Ec4_reactions_idx.flatten()]\n",
    "    m4.addConstr(S4 @ rxns4 + S4_ex @ rxns4_ex == np.zeros((S4.shape[0],)), name='internal_fba4');\n",
    "\n",
    "    m4.params.Method = 0;\n",
    "    m4.update();\n",
    "    m4.optimize();\n",
    "    \n",
    "    # Check degeneracy.\n",
    "    primal_basis1 = rxns1.VBasis == 0\n",
    "    primal_basis1_ex = rxns1_ex.VBasis == 0\n",
    "    nonbasic_constraints1 = np.array(m1.CBasis) != 0\n",
    "\n",
    "    active_basic1_lb = np.where(rxns1.X[primal_basis1] - lb1[primal_basis1] == 0)[0]\n",
    "    active_basic1_ub = np.where(ub1[primal_basis1] - rxns1.X[primal_basis1] == 0)[0]\n",
    "    active_basic1_ex_lb = np.where(rxns1_ex.X[primal_basis1_ex] - lb1_ex[primal_basis1_ex] == 0)[0]\n",
    "    active_basic1_ex_ub = np.where(ub1_ex[primal_basis1_ex] - rxns1_ex.X[primal_basis1_ex] == 0)[0]\n",
    "\n",
    "    if len(active_basic1_lb) == 0 and len(active_basic1_ub) == 0 and len(active_basic1_ex_lb) == 0 and len(active_basic1_ex_ub) == 0:\n",
    "        degenerate = False\n",
    "    else:\n",
    "        degenerate = True\n",
    "\n",
    "    if degenerate:\n",
    "        raise Exception('Ec1 problem is degenerate')\n",
    "\n",
    "    primal_basis2 = rxns2.VBasis == 0\n",
    "    primal_basis2_ex = rxns2_ex.VBasis == 0\n",
    "    nonbasic_constraints2 = np.array(m2.CBasis) != 0\n",
    "\n",
    "    active_basic2_lb = np.where(rxns2.X[primal_basis2] - lb2[primal_basis2] == 0)[0]\n",
    "    active_basic2_ub = np.where(ub2[primal_basis2] - rxns2.X[primal_basis2] == 0)[0]\n",
    "    active_basic2_ex_lb = np.where(rxns2_ex.X[primal_basis2_ex] - lb2_ex[primal_basis2_ex] == 0)[0]\n",
    "    active_basic2_ex_ub = np.where(ub2_ex[primal_basis2_ex] - rxns2_ex.X[primal_basis2_ex] == 0)[0]\n",
    "\n",
    "    if len(active_basic2_lb) == 0 and len(active_basic2_ub) == 0 and len(active_basic2_ex_lb) == 0 and len(active_basic2_ex_ub) == 0:\n",
    "        degenerate = False\n",
    "    else:\n",
    "        degenerate = True\n",
    "\n",
    "    if degenerate:\n",
    "        raise Exception('Ec2 problem is degenerate')\n",
    "\n",
    "    primal_basis3 = rxns3.VBasis == 0\n",
    "    primal_basis3_ex = rxns3_ex.VBasis == 0\n",
    "    nonbasic_constraints3 = np.array(m3.CBasis) != 0\n",
    "\n",
    "    active_basic3_lb = np.where(rxns3.X[primal_basis3] - lb3[primal_basis3] == 0)[0]\n",
    "    active_basic3_ub = np.where(ub3[primal_basis3] - rxns3.X[primal_basis3] == 0)[0]\n",
    "    active_basic3_ex_lb = np.where(rxns3_ex.X[primal_basis3_ex] - lb3_ex[primal_basis3_ex] == 0)[0]\n",
    "    active_basic3_ex_ub = np.where(ub3_ex[primal_basis3_ex] - rxns3_ex.X[primal_basis3_ex] == 0)[0]\n",
    "\n",
    "    if len(active_basic3_lb) == 0 and len(active_basic3_ub) == 0 and len(active_basic3_ex_lb) == 0 and len(active_basic3_ex_ub) == 0:\n",
    "        degenerate = False\n",
    "    else:\n",
    "        degenerate = True\n",
    "\n",
    "    if degenerate:\n",
    "        raise Exception('Ec3 problem is degenerate')\n",
    "\n",
    "    primal_basis4 = rxns4.VBasis == 0\n",
    "    primal_basis4_ex = rxns4_ex.VBasis == 0\n",
    "    nonbasic_constraints4 = np.array(m4.CBasis) != 0\n",
    "\n",
    "    active_basic4_lb = np.where(rxns4.X[primal_basis4] - lb4[primal_basis4] == 0)[0]\n",
    "    active_basic4_ub = np.where(ub4[primal_basis4] - rxns4.X[primal_basis4] == 0)[0]\n",
    "    active_basic4_ex_lb = np.where(rxns4_ex.X[primal_basis4_ex] - lb4_ex[primal_basis4_ex] == 0)[0]\n",
    "    active_basic4_ex_ub = np.where(ub4_ex[primal_basis4_ex] - rxns4_ex.X[primal_basis4_ex] == 0)[0]\n",
    "\n",
    "    if len(active_basic4_lb) == 0 and len(active_basic4_ub) == 0 and len(active_basic4_ex_lb) == 0 and len(active_basic4_ex_ub) == 0:\n",
    "        degenerate = False\n",
    "    else:\n",
    "        degenerate = True\n",
    "\n",
    "    if degenerate:\n",
    "        raise Exception('Ec4 problem is degenerate')\n",
    "        \n",
    "    U1 = np.where(ub1 - rxns1.X == 0)[0]\n",
    "    L1 = np.where(rxns1.X - lb1 == 0)[0]\n",
    "    F1 = np.where(np.logical_and(~np.isin(np.arange(J1), U1), ~np.isin(np.arange(J1), L1)))[0]\n",
    "    L1_ex = np.where(rxns1_ex.X - lb1_ex == 0)[0]\n",
    "    F1_ex = np.where(~np.isin(np.arange(Jl), L1_ex))[0]\n",
    "\n",
    "    U2 = np.where(ub2 - rxns2.X == 0)[0]\n",
    "    L2 = np.where(rxns2.X - lb2 == 0)[0]\n",
    "    F2 = np.where(np.logical_and(~np.isin(np.arange(J2), U2), ~np.isin(np.arange(J2), L2)))[0]\n",
    "    L2_ex = np.where(rxns2_ex.X - lb2_ex == 0)[0]\n",
    "    F2_ex = np.where(~np.isin(np.arange(Jl), L2_ex))[0]\n",
    "\n",
    "    U3 = np.where(ub3 - rxns3.X == 0)[0]\n",
    "    L3 = np.where(rxns3.X - lb3 == 0)[0]\n",
    "    F3 = np.where(np.logical_and(~np.isin(np.arange(J3), U3), ~np.isin(np.arange(J3), L3)))[0]\n",
    "    L3_ex = np.where(rxns3_ex.X - lb3_ex == 0)[0]\n",
    "    F3_ex = np.where(~np.isin(np.arange(Jl), L3_ex))[0]\n",
    "\n",
    "    U4 = np.where(ub4 - rxns4.X == 0)[0]\n",
    "    L4 = np.where(rxns4.X - lb4 == 0)[0]\n",
    "    F4 = np.where(np.logical_and(~np.isin(np.arange(J4), U4), ~np.isin(np.arange(J4), L4)))[0]\n",
    "    L4_ex = np.where(rxns4_ex.X - lb4_ex == 0)[0]\n",
    "    F4_ex = np.where(~np.isin(np.arange(Jl), L4_ex))[0]\n",
    "    \n",
    "    Omega1 = sparse.csr_matrix((sum(nonbasic_constraints1) + len(L1) + len(U1) + len(L1_ex), J1 + Jl))\n",
    "    Omega2 = sparse.csr_matrix((sum(nonbasic_constraints2) + len(L2) + len(U2) + len(L2_ex), J2 + Jl))\n",
    "    Omega3 = sparse.csr_matrix((sum(nonbasic_constraints3) + len(L3) + len(U3) + len(L3_ex), J3 + Jl))\n",
    "    Omega4 = sparse.csr_matrix((sum(nonbasic_constraints4) + len(L4) + len(U4) + len(L4_ex), J4 + Jl))\n",
    "\n",
    "    Omega1[0:sum(nonbasic_constraints1), 0:len(L1)] = S1[nonbasic_constraints1, :][:, L1]\n",
    "    Omega2[0:sum(nonbasic_constraints2), 0:len(L2)] = S2[nonbasic_constraints2, :][:, L2]\n",
    "    Omega3[0:sum(nonbasic_constraints3), 0:len(L3)] = S3[nonbasic_constraints3, :][:, L3]\n",
    "    Omega4[0:sum(nonbasic_constraints4), 0:len(L4)] = S4[nonbasic_constraints4, :][:, L4]\n",
    "\n",
    "    Omega1[0:sum(nonbasic_constraints1), len(L1):len(L1)+len(U1)] = S1[nonbasic_constraints1, :][:, U1]\n",
    "    Omega2[0:sum(nonbasic_constraints2), len(L2):len(L2)+len(U2)] = S2[nonbasic_constraints2, :][:, U2]\n",
    "    Omega3[0:sum(nonbasic_constraints3), len(L3):len(L3)+len(U3)] = S3[nonbasic_constraints3, :][:, U3]\n",
    "    Omega4[0:sum(nonbasic_constraints4), len(L4):len(L4)+len(U4)] = S4[nonbasic_constraints4, :][:, U4]\n",
    "\n",
    "    Omega1[0:sum(nonbasic_constraints1), len(L1)+len(U1):len(L1)+len(U1)+len(F1)] = S1[nonbasic_constraints1, :][:, F1]\n",
    "    Omega2[0:sum(nonbasic_constraints2), len(L2)+len(U2):len(L2)+len(U2)+len(F2)] = S2[nonbasic_constraints2, :][:, F2]\n",
    "    Omega3[0:sum(nonbasic_constraints3), len(L3)+len(U3):len(L3)+len(U3)+len(F3)] = S3[nonbasic_constraints3, :][:, F3]\n",
    "    Omega4[0:sum(nonbasic_constraints4), len(L4)+len(U4):len(L4)+len(U4)+len(F4)] = S4[nonbasic_constraints4, :][:, F4]\n",
    "\n",
    "    Omega1[0:sum(nonbasic_constraints1), len(L1)+len(U1)+len(F1):len(L1)+len(U1)+len(F1)+len(L1_ex)] = S1_ex[nonbasic_constraints1, :][:, L1_ex]\n",
    "    Omega2[0:sum(nonbasic_constraints2), len(L2)+len(U2)+len(F2):len(L2)+len(U2)+len(F2)+len(L2_ex)] = S2_ex[nonbasic_constraints2, :][:, L2_ex]\n",
    "    Omega3[0:sum(nonbasic_constraints3), len(L3)+len(U3)+len(F3):len(L3)+len(U3)+len(F3)+len(L3_ex)] = S3_ex[nonbasic_constraints3, :][:, L3_ex]\n",
    "    Omega4[0:sum(nonbasic_constraints4), len(L4)+len(U4)+len(F4):len(L4)+len(U4)+len(F4)+len(L4_ex)] = S4_ex[nonbasic_constraints4, :][:, L4_ex]\n",
    "\n",
    "    Omega1[0:sum(nonbasic_constraints1), len(L1)+len(U1)+len(F1)+len(L1_ex):] = S1_ex[nonbasic_constraints1, :][:, F1_ex]\n",
    "    Omega2[0:sum(nonbasic_constraints2), len(L2)+len(U2)+len(F2)+len(L2_ex):] = S2_ex[nonbasic_constraints2, :][:, F2_ex]\n",
    "    Omega3[0:sum(nonbasic_constraints3), len(L3)+len(U3)+len(F3)+len(L3_ex):] = S3_ex[nonbasic_constraints3, :][:, F3_ex]\n",
    "    Omega4[0:sum(nonbasic_constraints4), len(L4)+len(U4)+len(F4)+len(L4_ex):] = S4_ex[nonbasic_constraints4, :][:, F4_ex]\n",
    "\n",
    "    Omega1[sum(nonbasic_constraints1):sum(nonbasic_constraints1)+len(L1), 0:len(L1)] = np.identity(len(L1))\n",
    "    Omega2[sum(nonbasic_constraints2):sum(nonbasic_constraints2)+len(L2), 0:len(L2)] = np.identity(len(L2))\n",
    "    Omega3[sum(nonbasic_constraints3):sum(nonbasic_constraints3)+len(L3), 0:len(L3)] = np.identity(len(L3))\n",
    "    Omega4[sum(nonbasic_constraints4):sum(nonbasic_constraints4)+len(L4), 0:len(L4)] = np.identity(len(L4))\n",
    "\n",
    "    Omega1[sum(nonbasic_constraints1)+len(L1):sum(nonbasic_constraints1)+len(L1)+len(U1), len(L1):len(L1)+len(U1)] = np.identity(len(U1))\n",
    "    Omega2[sum(nonbasic_constraints2)+len(L2):sum(nonbasic_constraints2)+len(L2)+len(U2), len(L2):len(L2)+len(U2)] = np.identity(len(U2))\n",
    "    Omega3[sum(nonbasic_constraints3)+len(L3):sum(nonbasic_constraints3)+len(L3)+len(U3), len(L3):len(L3)+len(U3)] = np.identity(len(U3))\n",
    "    Omega4[sum(nonbasic_constraints4)+len(L4):sum(nonbasic_constraints4)+len(L4)+len(U4), len(L4):len(L4)+len(U4)] = np.identity(len(U4))\n",
    "\n",
    "    Omega1[sum(nonbasic_constraints1)+len(L1)+len(U1):, len(L1)+len(U1)+len(F1):len(L1)+len(U1)+len(F1)+len(L1_ex)] = np.identity(len(L1_ex))\n",
    "    Omega2[sum(nonbasic_constraints2)+len(L2)+len(U2):, len(L2)+len(U2)+len(F2):len(L2)+len(U2)+len(F2)+len(L2_ex)] = np.identity(len(L2_ex))\n",
    "    Omega3[sum(nonbasic_constraints3)+len(L3)+len(U3):, len(L3)+len(U3)+len(F3):len(L3)+len(U3)+len(F3)+len(L3_ex)] = np.identity(len(L3_ex))\n",
    "    Omega4[sum(nonbasic_constraints4)+len(L4)+len(U4):, len(L4)+len(U4)+len(F4):len(L4)+len(U4)+len(F4)+len(L4_ex)] = np.identity(len(L4_ex))\n",
    "    \n",
    "    # Now construct Pi matrices.\n",
    "    Pi1 = sp_linalg.inv(Omega1)\n",
    "    Pi2 = sp_linalg.inv(Omega2)\n",
    "    Pi3 = sp_linalg.inv(Omega3)\n",
    "    Pi4 = sp_linalg.inv(Omega4)\n",
    "\n",
    "    Pi1 = Pi1[np.concatenate([L1_ex, F1_ex]).flatten(), :]\n",
    "    Pi2 = Pi2[np.concatenate([L2_ex, F2_ex]).flatten(), :]\n",
    "    Pi3 = Pi3[np.concatenate([L3_ex, F3_ex]).flatten(), :]\n",
    "    Pi4 = Pi4[np.concatenate([L4_ex, F4_ex]).flatten(), :]\n",
    "\n",
    "    Pi1 = Pi1[:, L1_ex.flatten()]\n",
    "    Pi2 = Pi2[:, L2_ex.flatten()]\n",
    "    Pi3 = Pi3[:, L3_ex.flatten()]\n",
    "    Pi4 = Pi4[:, L4_ex.flatten()]\n",
    "    \n",
    "    A = sparse.identity(4*Jl).tocsr()\n",
    "    B_rhs = sparse.csr_matrix((4*Jl, Jl))\n",
    "    \n",
    "    # Make first row of A.\n",
    "    A[0:Jl, Jl:2*Jl] = (bm2 / bm1) * Pi1 * sparse.identity(Jl).tocsr()[L1_ex, :]\n",
    "    A[0:Jl, 2*Jl:3*Jl] = (bm3 / bm1) * Pi1 * sparse.identity(Jl).tocsr()[L1_ex, :]\n",
    "    A[0:Jl, 3*Jl:] = (bm4 / bm1) * Pi1 * sparse.identity(Jl).tocsr()[L1_ex, :]\n",
    "\n",
    "    # Make second row of A.\n",
    "    A[Jl:2*Jl, 0:Jl] = (bm1 / bm2) * Pi2 * sparse.identity(Jl).tocsr()[L2_ex, :]\n",
    "    A[Jl:2*Jl, 2*Jl:3*Jl] = (bm3 / bm2) * Pi2 * sparse.identity(Jl).tocsr()[L2_ex, :]\n",
    "    A[Jl:2*Jl, 3*Jl:] = (bm4 / bm2) * Pi2 * sparse.identity(Jl).tocsr()[L2_ex, :]\n",
    "\n",
    "    # Make third row of A.\n",
    "    A[2*Jl:3*Jl, 0:Jl] = (bm1 / bm3) * Pi3 * sparse.identity(Jl).tocsr()[L3_ex, :]\n",
    "    A[2*Jl:3*Jl, Jl:2*Jl] = (bm2 / bm3) * Pi3 * sparse.identity(Jl).tocsr()[L3_ex, :]\n",
    "    A[2*Jl:3*Jl, 3*Jl:] = (bm4 / bm3) * Pi3 * sparse.identity(Jl).tocsr()[L3_ex, :]\n",
    "\n",
    "    # Make fourth row of A.\n",
    "    A[3*Jl:, 0:Jl] = (bm1 / bm4) * Pi4 * sparse.identity(Jl).tocsr()[L4_ex, :]\n",
    "    A[3*Jl:, Jl:2*Jl] = (bm2 / bm4) * Pi4 * sparse.identity(Jl).tocsr()[L4_ex, :]\n",
    "    A[3*Jl:, 2*Jl:3*Jl] = (bm3 / bm4) * Pi4 * sparse.identity(Jl).tocsr()[L4_ex, :]\n",
    "\n",
    "    # Add to right-hand side B.\n",
    "    B_rhs[0:Jl,:] = -(1/bm1) * Pi1 * sparse.identity(Jl).tocsr()[L1_ex, :]\n",
    "    B_rhs[Jl:2*Jl,:] = -(1/bm2) * Pi2 * sparse.identity(Jl).tocsr()[L2_ex, :]\n",
    "    B_rhs[2*Jl:3*Jl,:] = -(1/bm3) * Pi3 * sparse.identity(Jl).tocsr()[L3_ex, :]\n",
    "    B_rhs[3*Jl:, :] = -(1/bm4) * Pi4 * sparse.identity(Jl).tocsr()[L4_ex, :]\n",
    "\n",
    "    # Now solve for the B matrices.\n",
    "    B = sp_linalg.spsolve(A, B_rhs)\n",
    "    B1 = B[0:Jl, :]\n",
    "    B2 = B[Jl:2*Jl, :]\n",
    "    B3 = B[2*Jl:3*Jl, :]\n",
    "    B4 = B[3*Jl:, :]\n",
    "    \n",
    "    return (B1, B2, B3, B4)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_start_time = time.time()\n",
    "\n",
    "for i in range(len(steady_states)):\n",
    "    print('i: ', i)\n",
    "    if i > 50:\n",
    "        continue\n",
    "    biomasses, x1, x2, x3, x4 = steady_states[i]\n",
    "    bm1, bm2, bm3, bm4 = biomasses\n",
    "    try:\n",
    "        B1, B2, B3, B4 = make_B_mats(x1, x2, x3, x4, bm1, bm2, bm3, bm4, 1e-8)\n",
    "        E = np.where(bm1 * x1[J1:] + bm2 * x2[J2:] + bm3 * x3[J3:] + bm4 * x4[J4:] - reaction_lb[lumen_reactions_idx.flatten()] < 1e-6)[0]\n",
    "        inv_val = invasion_stability_opt(bm1, bm2, bm3, bm4, B1, B2, B3, B4, E)\n",
    "        if inv_val < death_rate:\n",
    "            uninvaded_steady_states.append(steady_states[i])\n",
    "        else:\n",
    "            invaded_steady_states.append(steady_states[i])\n",
    "    except:\n",
    "        print('\\n')\n",
    "        print('in except')\n",
    "        print('\\n')\n",
    "        B1, B2, B3, B4 = make_B_mats(x1, x2, x3, x4, bm1, bm2, bm3, bm4, 1e-6)\n",
    "        E = np.where(bm1 * x1[J1:] + bm2 * x2[J2:] + bm3 * x3[J3:] + bm4 * x4[J4:] - reaction_lb[lumen_reactions_idx.flatten()] < 1e-6)[0]\n",
    "        inv_val = invasion_stability_opt(bm1, bm2, bm3, bm4, B1, B2, B3, B4, E)\n",
    "        if inv_val < death_rate:\n",
    "            uninvaded_steady_states.append(steady_states[i])\n",
    "        else:\n",
    "            invaded_steady_states.append(steady_states[i])\n",
    "\n",
    "total_end_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(invaded_steady_states, open(\"invaded_steady_states.p\", \"wb\"))\n",
    "pickle.dump(uninvaded_steady_states, open(\"uninvaded_steady_states.p\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e32fce6a6c3fd48953af81f35dd8f0e6fbd7c4087b039bf734f43a70745cec5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
